{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8z5cONg8rUrX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# List Algorithms\n",
    "\n",
    "## Programming Fundamentals (NB19)\n",
    "\n",
    "### MIEIC/2020-21\n",
    "\n",
    "#### João Correia Lopes\n",
    "\n",
    "FEUP/DEI and INESC TEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZzE7pYorju5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Goals\n",
    "\n",
    "By the end of this class, the student should be able to:\n",
    "\n",
    "- Explain and implement linear search and binary search\n",
    "\n",
    "- Describe other algorithms that work with lists\n",
    "\n",
    "- Compare the performance of those algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eR5Lh1jNroE2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bibliography\n",
    "\n",
    "- Peter Wentworth, Jeffrey Elkner, Allen B. Downey, and Chris Meyers, *How to Think Like a Computer Scientist — Learning with Python 3 (RLE)*, 2012 (Chapter 14)\n",
    "[[HTML]](http://openbookproject.net/thinkcs/python/english3e/list_algorithms.html)\n",
    "\n",
    "- Brad Miller and David Ranum, *Problem Solving with Algorithms and Data Structures using Python* (Section 6.3, Section 6.4)\n",
    "[[HTML]](https://runestone.academy/runestone/books/published/pythonds/SortSearch/toctree.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rp0xhM5RT_-a",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorithms that work with lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5eYko3wXgUNB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### List Algorithms\n",
    "\n",
    "> **And now for something completely different!** (*Monty Python's Flying Circus*)\n",
    "\n",
    "- Rather than introduce more programming constructs, or new Python\n",
    "    syntax and features\n",
    "\n",
    "- ... we focus on some algorithms that work with lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhFIuTRnhL0Z",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Alice in Wonderland\n",
    "\n",
    "- Examples work with the book \"Alice in Wonderland\" and a \"vocabulary file\"\n",
    "\n",
    "![alice](images/19/alice_cover.jpg)\n",
    "\n",
    "$\\Rightarrow$\n",
    "[Alice in Wonderland](http://openbookproject.net/thinkcs/python/english3e/_downloads/alice_in_wonderland.txt)  \n",
    "$\\Rightarrow$\n",
    "[Vocabulary](http://openbookproject.net/thinkcs/python/english3e/_downloads/vocab.txt)  \n",
    "$\\Rightarrow$\n",
    "[Alice's Adventures in Wonderland by Lewis Carroll](http://www.gutenberg.org/ebooks/19033)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHTEB65De4mS",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The linear search algorithm [14.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jIhDbG2jZPM",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The linear search algorithm\n",
    "\n",
    "- We'd like to know the index where a specific item occurs within in a\n",
    "    list of items\n",
    "\n",
    "- Specifically, we'll return the index of the item if it is found, or\n",
    "    we'll return -1 if the item doesn't occur in the list\n",
    "\n",
    "![image](images/19/linear.png)\n",
    "\n",
    "$\\Rightarrow$\n",
    "[Problem Solving with Algorithms...](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheSequentialSearch.html)  \n",
    "$\\Rightarrow$\n",
    "<https://github.com/fpro-feup/public/blob/master/lectures/19/linear.py>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wvUwflWk0JG",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear search\n",
    "\n",
    "```\n",
    "   def search_linear(xs, target):\n",
    "       \"\"\" Find and return the index of target in sequence xs, or -1 \"\"\"\n",
    "       for (i, v) in enumerate(xs):\n",
    "           if v == target:\n",
    "               return i\n",
    "       return -1\n",
    "```\n",
    "\n",
    "- Searching all items of a sequence from first to last is called a\n",
    "    **linear search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRvuuhJ6691g",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a list of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mMNTMwe6685",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ls = [2, 3, 5, 7, 11, 13, 17, 23, 29, 31, 37, 43, 47, 53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "weFXHg9l7HBL",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Find and return the index of `target` in the given sequence `xs`, or -1 when not found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szLAaeAQ7DJS",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def search_linear(xs, target):\n",
    "    \"\"\" Find and return the index of target in sequence xs, or -1 \"\"\"\n",
    "    for (i, v) in enumerate(xs):\n",
    "        if v == target:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsZXksjK7RHh",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(search_linear(ls, 1))\n",
    "print(search_linear(ls, 17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dFNS8PYlL4Q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Probing\n",
    "\n",
    "- Each time we check whether `v == target` we'll call it a **probe**\n",
    "\n",
    "    - We like to count probes as a measure of how efficient our\n",
    "        algorithm is\n",
    "\n",
    "    - this will be a good enough indication of how long our algorithm\n",
    "        will take to execute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-UVOerLlU6Q",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Linear searching is characterized by the fact that the number of\n",
    "    probes needed to find some target depends directly on the length of\n",
    "    the list\n",
    "\n",
    "- On average, when the target is present, we're going to need to go\n",
    "    about halfway through the list, or N/2 probes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omuWPdhmlaNG",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear Performance\n",
    "\n",
    "- We say that linear search has linear performance (linear meaning\n",
    "    *straight line*)\n",
    "\n",
    "- Analysis like this is pretty meaningless for small lists\n",
    "\n",
    "    - The computer is quick enough not to bother if the list only has\n",
    "        a handful of items\n",
    "\n",
    "- So generally, we're interested in the **scalability** of our\n",
    "    algorithms\n",
    "\n",
    "    - How do they perform if we throw bigger problems at them\n",
    "\n",
    "    - What happens for **really large** datasets, e.g. how does Google\n",
    "        search so brilliantly well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7dhwuoxe9yk",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A more realistic problem [14.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B06g3XuclqKq",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A more realistic problem\n",
    "\n",
    "- As children learn to read, there are expectations that their\n",
    "    vocabulary will grow\n",
    "\n",
    "- So a child of age 14 is expected to know more words than a child of\n",
    "    age 8\n",
    "\n",
    "- When prescribing reading books for a grade, an important question\n",
    "    might be:\n",
    "    \n",
    ">    **\"which words in this book are not in the expected\n",
    ">    vocabulary at this level?\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHQp6YAfbulX",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let us assume we can read a vocabulary of words into our program\n",
    "\n",
    "- Then read the text of a book, and split it into words\n",
    "\n",
    "$\\Rightarrow$\n",
    "<https://github.com/fpro-feup/public/blob/master/lectures/19/alice.py>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUSPCvmMb8kY",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An utility function we'll need later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrhbFrri7qN4",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def load_from_file(filename):\n",
    "    \"\"\" Read words from filename, return a string. \"\"\"\n",
    "    f = open(filename, \"r\")\n",
    "    file_content = f.read()\n",
    "    f.close()\n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Try it, to open the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vocab = load_from_file(\"files/vocab.txt\")\n",
    "type(vocab)\n",
    "print(\"There are\", len(vocab), \"chars in the vocabulary.\\nStarting with:\")\n",
    "vocab[:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M85CVyYWgrMK",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The basic strategy is to run through each of the words in the book,\n",
    " look it up in the vocabulary, and if it is not in the vocabulary,\n",
    " save it into a new resulting list which we return from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EBHLUntgyiC",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def find_unknown_words(vocab, wds):\n",
    "    \"\"\" Return a list of words in wds that do not occur in vocab. \"\"\"\n",
    "    result = []\n",
    "    for w in wds:\n",
    "        if (search_linear(vocab, w) < 0):  # linear search\n",
    "            result.append(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G92Grq2uiSHg",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Split vocabulary in words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3ncikuqiV1I",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def load_words_from_file(filename):\n",
    "    \"\"\" Read words from filename, return list of words. \"\"\"\n",
    "    file_content = load_from_file(filename)\n",
    "    wds = file_content.split()\n",
    "    return wds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USqNX3ctiboC",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now read a sensible size vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmAp458WigEp",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bigger_vocab = load_words_from_file(\"files/vocab.txt\")\n",
    "print(\"There are {0} words in the vocabulary.\\nStarting with:\\n{1} \"\n",
    "      .format(len(bigger_vocab), bigger_vocab[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UT_Pc1Bil1J",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Books are full of punctuation, and have mixtures of lowercase and uppercase letters. We need to clean up the contents of the book. \n",
    "\n",
    "This will involve removing punctuation, and converting everything to the same case (lowercase, because our vocabulary is all in lowercase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUtDytCliyd9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def text_to_words(the_text):\n",
    "    \"\"\" return a list of words with all punctuation removed, and all in lowercase. \"\"\"\n",
    "    my_substitutions = the_text.maketrans(\n",
    "      # If you find any of these\n",
    "      \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\\\"#$%&()*+,-./:;<=>?@[]^_`{|}~'\\\\\",\n",
    "      # Replace them by these\n",
    "      \"abcdefghijklmnopqrstuvwxyz                                          \")\n",
    "    # Translate the text now.\n",
    "    cleaned_text = the_text.translate(my_substitutions)\n",
    "    wds = cleaned_text.split()\n",
    "    return wds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Try it, using an (in)famous quotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "str = \"I’m a lumberjack and I’m OK. I sleep all night and I work all day!\"\n",
    "print(str)\n",
    "clean_str = text_to_words(str)\n",
    "print(clean_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egzFpNl8i--O",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Get a clean book from a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swEcWrPFjDPD",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_words_in_book(filename):\n",
    "    \"\"\" Read a book from filename, and return a list of its words. \"\"\"\n",
    "    file_content = load_from_file(filename)\n",
    "    wds = text_to_words(file_content)\n",
    "    return wds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnjcfRs1jNIL",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we're ready to read in our book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvUdC5eWjWwl",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "book_words = get_words_in_book(\"files/AliceInWonderland.txt\")\n",
    "print(\"There are {0} words in the book.\\nStarting with:\\n{1}\"\n",
    "      .format(len(book_words), book_words[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2I00n64tjbHP",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Find the unknown words and make some timing measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCsDwb_mjh4v",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"Finding unknown words...\", end='')\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "missing_words = find_unknown_words(bigger_vocab, book_words)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(\" took {0:.4f} seconds.\".format(t1-t0))\n",
    "print()\n",
    "print(\"There are {0} unknown words.\\nStarting with:\\n{1}\"\n",
    "      .format(len(missing_words), missing_words[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cpl-uadGfFlN",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary Search [14.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qi5wf9jZmNfF",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Binary Search\n",
    "\n",
    "- If you were given a vocabulary and asked to tell if some word was\n",
    "    present, you'd probably start in the middle\n",
    "\n",
    "- You can do this because the vocabulary is ordered --- so you can\n",
    "    probe some word in the middle, and immediately realize that your\n",
    "    target was before (or perhaps after) the one you had probed\n",
    "\n",
    "- Applying this principle repeatedly leads us to a very much better\n",
    "    algorithm for searching in a list of items that are already ordered\n",
    "\n",
    "- This algorithm is called **binary search**\n",
    "\n",
    "- It is a good example of *divide and conquer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFRsSc-wnInQ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Region of Interest (ROI)\n",
    "\n",
    "- Our algorithm will start with the ROI set to all the items in the\n",
    "    list\n",
    "\n",
    "- On the first probe in the middle of the ROI, there are three\n",
    "    possible outcomes:\n",
    "\n",
    "    - either we find the target\n",
    "\n",
    "    - or we learn that we can discard the top half of the ROI\n",
    "\n",
    "    - or we learn that we can discard the bottom half of the ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q8knEn2YcjlZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Trying with 54...\n",
    "\n",
    "![image](images/19/binary.png)\n",
    "\n",
    "$\\Rightarrow$\n",
    "[Problem Solving with Algorithms...](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheBinarySearch.html)  \n",
    "$\\Rightarrow$\n",
    "<https://github.com/fpro-feup/public/blob/master/lectures/19/binary.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8j0WQZkcu-5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def search_binary(xs, target):\n",
    "    \"\"\" Find and return the index of key in sequence xs, or -1 \"\"\"\n",
    "    lb = 0        # lower bound\n",
    "    ub = len(xs)  # upper bound\n",
    "    while True:\n",
    "        if lb == ub:   # If region of interest (ROI) becomes empty\n",
    "            return -1  # NOT found!\n",
    "\n",
    "        # Next probe should be in the middle of the ROI\n",
    "        mid_index = (lb + ub) // 2\n",
    "\n",
    "        # Fetch the item at that position\n",
    "        item_at_mid = xs[mid_index]\n",
    "\n",
    "        # comment next if not debugging\n",
    "        print(\"ROI[{0}:{1}](size={2}), probed='{3}', target='{4}'\"\n",
    "              .format(lb, ub, ub-lb, item_at_mid, target))\n",
    "\n",
    "        # How does the probed item compare to the target?\n",
    "        if item_at_mid == target:\n",
    "            return mid_index      # Found it!\n",
    "        if item_at_mid < target:\n",
    "            lb = mid_index + 1    # Use upper half of ROI next time\n",
    "        else:\n",
    "            ub = mid_index        # Use lower half of ROI next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The debug print statements, give us a trace of the probes done during a search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtenC58KdpX6",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ls = [2, 3, 5, 7, 11, 13, 17, 23, 29, 31, 37, 43, 47]  # len(ls) = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e26g93u9dk5x",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Try it and have a look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dy3wmT5vduuH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(search_binary(ls, 4))\n",
    "print(search_binary(ls, 17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UdycVjajXGA",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ls = [2, 3, 5, 7, 11, 13, 17, 23, 29, 31, 37, 43, 47, 53]  # len(ls) = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "di3sdVGvdz15",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(search_binary(ls, 17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LkSZA3fny_4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Back to \"A more realistic problem\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsGK5CJQnJXu",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, we'll use `binary_search()` to find the unknown words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6gU66-kOMK8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def search_binary(xs, target):\n",
    "    \"\"\" Find and return the index of key in sequence xs, or -1 \"\"\"\n",
    "    lb = 0        # lower bound\n",
    "    ub = len(xs)  # upper bound\n",
    "    while True:\n",
    "        if lb == ub:   # If region of interest (ROI) becomes empty\n",
    "            return -1  # NOT found!\n",
    "        mid_index = (lb + ub) // 2\n",
    "        item_at_mid = xs[mid_index]\n",
    "        if item_at_mid == target:\n",
    "            return mid_index      # Found it!\n",
    "        if item_at_mid < target:\n",
    "            lb = mid_index + 1    # Use upper half of ROI next time\n",
    "        else:\n",
    "            ub = mid_index        # Use lower half of ROI next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74-crKvtnRTB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def find_unknown_words(vocab, wds):\n",
    "    \"\"\" Return a list of words in wds that do not occur in vocab \"\"\"\n",
    "    result = []\n",
    "    for w in wds:\n",
    "        if (search_binary(vocab, w) < 0):  # binary search\n",
    "            result.append(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELAm-W2Fni9i",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"Finding unknown words...\", end='')\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "missing_words = find_unknown_words(bigger_vocab, book_words)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(\" took {0:.4f} seconds.\".format(t1-t0))\n",
    "print()\n",
    "print(\"There are {0} unknown words.\\nStarting with:\\n{1}\"\n",
    "      .format(len(missing_words), missing_words[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDgT4PFkvVip",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "$\\Rightarrow$\n",
    "<https://github.com/fpro-feup/public/blob/master/lectures/19/alice.py>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5itkKW9nZAH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What a spectacular difference: more than 200 times faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpc4l0IhfKL2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Removing adjacent duplicates from a list [14.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gl6DdZgVoH72",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Removing adjacent duplicates from a list\n",
    "\n",
    "- We often want to get the unique elements in a list, i.e. produce a\n",
    "    new list in which each different element occurs just once\n",
    "\n",
    "- Consider our case of looking for words in *Alice in Wonderland* that\n",
    "    are not in our vocabulary\n",
    "\n",
    "- We had a report that there are 3398 such words, but there are\n",
    "    duplicates in that list\n",
    "\n",
    "- In fact, the word \"alice\" occurs 398 times in the book, and it is\n",
    "    not in our vocabulary!\n",
    "\n",
    "- How should we remove these duplicates?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKKhHJ-KoZ8N",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- A good approach is to sort the list, then **remove all adjacent\n",
    "    duplicates**\n",
    "\n",
    "$\\Rightarrow$\n",
    "<https://github.com/fpro-feup/public/blob/master/lectures/19/adjacent.py>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8zAkIace6p2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a sorted list, to remove duplicates, we simply have to remember the most recent item that was inserted into the result, and avoid inserting it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMQoIzdNfBMT",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def remove_adjacent_dups(xs):\n",
    "    \"\"\" Return a new list in which all adjacent duplicates from xs\n",
    "        have been removed. \"\"\"\n",
    "    result = []\n",
    "    most_recent_elem = None\n",
    "    for e in xs:\n",
    "        if e != most_recent_elem:\n",
    "            result.append(e)\n",
    "            most_recent_elem = e\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYTLIEQXfM7w",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ls = friends = [\"Joe\", \"Zoe\", \"Joe\", \"Angelina\", \"Zuki\", \"Thandi\", \"Zuki\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pljmEAfwfS7A",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(ls)\n",
    "ls.sort()\n",
    "print(ls)\n",
    "print(remove_adjacent_dups(ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5zSQSp4fma8",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The amount of work done in this algorithm is linear — each item in the list `xs` causes the loop to execute exactly once, and there are no nested loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zxC_nMjout1",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Back to \"A more realistic problem\"\n",
    "\n",
    "- Let us go back now to our analysis of *Alice in Wonderland*\n",
    "\n",
    "- Before checking the words in the book against the vocabulary, we'll\n",
    "    sort those words into order, and eliminate duplicates\n",
    "\n",
    "$\\Rightarrow$\n",
    "<https://github.com/fpro-feup/public/blob/master/lectures/19/alice2.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5Q6rhGxpdvd",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "all_words = get_words_in_book(\"files/AliceInWonderland.txt\")\n",
    "all_words.sort()\n",
    "book_words = remove_adjacent_dups(all_words)\n",
    "print()\n",
    "print(\"There are {0} words in the book. Only {1} are unique.\"\n",
    "      .format(len(all_words), len(book_words)))\n",
    "print(\"The first 12 words are:\\n{0}\".format(book_words[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xP28lFKPpozW",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- Lewis Carroll was able to write a classic piece of literature using\n",
    "    only 2570 different words!\n",
    "\n",
    "- and our `book_words` in 10 times smaller..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQ537BpDfPwr",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Merging sorted lists [14.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbOjuZ4wo3P2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Merging sorted lists\n",
    "\n",
    "- Suppose we have two sorted lists (`xs` and `yx`)\n",
    "\n",
    "- Devise an algorithm to merge them together into a single sorted list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8g00vp2qpXwb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- A **simple but inefficient** algorithm could be to simply append the\n",
    "    two lists together, and sort the result\n",
    "\n",
    "- But this doesn't take advantage of the fact that the two lists are\n",
    "    already sorted\n",
    "\n",
    "    - It is going to have poor scalability and performance for very\n",
    "        large lists\n",
    "\n",
    "```\n",
    "   newlist = xs + ys\n",
    "   newlist.sort()\n",
    "```\n",
    "\n",
    "$\\Rightarrow$\n",
    "<https://github.com/fpro-feup/public/blob/master/lectures/19/merge.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sn7mZIyZqajs",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def merge(xs, ys):\n",
    "    \"\"\" Merge sorted lists xs and ys. Return a sorted result. \"\"\"\n",
    "    result = []\n",
    "    xi = 0   # i-th element of xs\n",
    "    yi = 0   # i-th element of ys\n",
    "\n",
    "    while True:\n",
    "        if xi >= len(xs):           # If xs list is finished,\n",
    "            result.extend(ys[yi:])  # Add remaining items from ys\n",
    "            return result           # And we're done.\n",
    "\n",
    "        if yi >= len(ys):           # Same again, but swap roles\n",
    "            result.extend(xs[xi:])\n",
    "            return result\n",
    "\n",
    "        # Both lists still have items, copy smaller item to result.\n",
    "        if xs[xi] <= ys[yi]:\n",
    "            result.append(xs[xi])\n",
    "            xi += 1\n",
    "        else:\n",
    "            result.append(ys[yi])\n",
    "            yi += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldWzQfyDqzyo",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Try it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2svVYoxxq1XL",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ls1 = friends = [\"Joe\", \"Zoe\", \"Brad\"]\n",
    "ls2 = friends = [\"Angelina\", \"Zuki\", \"Thandi\", \"Paris\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zKjjm4Hq63B",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ls1.sort()\n",
    "print(ls1)\n",
    "ls2.sort()\n",
    "print(ls2)\n",
    "ls3 = merge(ls1, ls2)\n",
    "print(ls3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qynuHZnvfTrU",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Alice in Wonderland, again! [14.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gsrm2Tnko_-g",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Back to \"A more realistic problem\"\n",
    "\n",
    "- Let us go back now to our analysis of *Alice in Wonderland*\n",
    "\n",
    "- Previously we sorted the words from the book, and eliminated\n",
    "    duplicates\n",
    "\n",
    "- Our vocabulary is also sorted\n",
    "\n",
    "- So, to find all items in the second list that are not in the first\n",
    "    list, would be another way to implement `find_unknown_words`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n55JgkpErOtP",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead of searching for every word in the dictionary (either by linear or binary search), why not use a variant of the \"merge sorted\" algorithm to return the words that occur in the book, but not in the vocabulary.\n",
    "\n",
    "$\\Rightarrow$\n",
    "<https://github.com/fpro-feup/public/blob/master/lectures/19/alice3.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6O_o05rrI_E",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def find_unknowns_merge_pattern(vocab, wds):\n",
    "    \"\"\" Both the vocab and wds must be sorted.  Return a new\n",
    "        list of words from wds that do not occur in vocab.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    xi = 0\n",
    "    yi = 0\n",
    "\n",
    "    while True:\n",
    "        if xi >= len(vocab):        # there's no more words in vocab\n",
    "            result.extend(wds[yi:])\n",
    "            return result\n",
    "\n",
    "        if yi >= len(wds):          # there's no more words to check\n",
    "            return result\n",
    "\n",
    "        if vocab[xi] == wds[yi]:    # good, word exists in vocab\n",
    "            yi += 1\n",
    "\n",
    "        elif vocab[xi] < wds[yi]:   # move past this vocab word\n",
    "            xi += 1\n",
    "\n",
    "        else:                       # word is not in vocab\n",
    "            result.append(wds[yi])\n",
    "            yi += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6i19Ih1frgHq",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Find the unknown words, again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGm2LXherkWV",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "all_words = get_words_in_book(\"files/AliceInWonderland.txt\")\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "all_words.sort()\n",
    "book_words = remove_adjacent_dups(all_words)\n",
    "missing_words = find_unknowns_merge_pattern(bigger_vocab, book_words)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(\"There are {0} unknown words.\".format(len(missing_words)))\n",
    "print(\"That took {0:.4f} seconds.\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "126ksd3WryJQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Even more stunning performance here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0vt8ef8pGCF",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "- Let's review what we've done.\n",
    "\n",
    "    - We started with a word-by-word **linear lookup** in the\n",
    "        vocabulary that ran in about 50 seconds\n",
    "\n",
    "    - We implemented a clever **binary search**, and got that down to\n",
    "        0.22 seconds, more than 200 times faster\n",
    "\n",
    "    - But then we did something even better: we sorted the words from\n",
    "        the book, eliminated duplicates, and used a **merging pattern**\n",
    "        to find words from the book that were not in the dictionary;\n",
    "        this was about five times faster than even the binary lookup\n",
    "        algorithm\n",
    "\n",
    "    - At the end, our algorithm is more than a 1000 times faster than\n",
    "        our first attempt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zz-UtV8ORH_t",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ticket to leave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-hchAExRRVh",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Moodle activity\n",
    "\n",
    "[LE19: List algorithms](https://moodle.up.pt/course/view.php?id=1738#section-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uV1OP6ahRYne",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "$\\Rightarrow$ \n",
    "[Go back to the Table of Contents](00-contents.ipynb)\n",
    "\n",
    "$\\Rightarrow$ \n",
    "[Read the Preface](00-preface.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "19-list-algorithms.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
